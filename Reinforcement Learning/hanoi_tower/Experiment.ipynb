{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import ray\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.algorithms import dqn, ppo\n",
    "\n",
    "from env import *\n",
    "from model import *\n",
    "from action_distribution import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/dn/w4zvyvvs1gl1zhr1dmd_92th0000gn/T/ipykernel_29562/1290334419.py:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 22:43:08,973\tINFO worker.py:1553 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.10.9</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.3.0</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.10.9', ray_version='2.3.0', ray_commit='cf7a56b4b0b648c324722df7c99c168e92ff0b45', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-03-11_22-43-07_395967_29562/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-03-11_22-43-07_395967_29562/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2023-03-11_22-43-07_395967_29562', 'metrics_export_port': 58430, 'gcs_address': '127.0.0.1:63829', 'address': '127.0.0.1:63829', 'dashboard_agent_listen_port': 52365, 'node_id': '5ec29603a685b135d79b01f249cb18526391a8421b57015ae37fbb48'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 22:43:09,718\tINFO algorithm_config.py:2899 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "2023-03-11 22:43:09,736\tINFO algorithm.py:506 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m Metal device set to: Apple M1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m systemMemory: 16.00 GB\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m maxCacheSize: 5.33 GB\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m Metal device set to: Apple M1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m systemMemory: 16.00 GB\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m maxCacheSize: 5.33 GB\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m Model: \"base_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m  obs_input (InputLayer)      [(None, 3, 4)]            0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m  flatten (Flatten)           (None, 12)                0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m  context (Dense)             (None, 16)                208       \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m  value_out (Dense)           (None, 1)                 17        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m Total params: 225\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m Trainable params: 225\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m Model: \"from_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m  ctx_input (InputLayer)      [(None, 16)]              0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m  from_logits (Dense)         (None, 3)                 51        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m Total params: 51\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m Trainable params: 51\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m Metal device set to: Apple M1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m systemMemory: 16.00 GB\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m maxCacheSize: 5.33 GB\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m Model: \"base_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m  obs_input (InputLayer)      [(None, 3, 4)]            0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m  flatten (Flatten)           (None, 12)                0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m  context (Dense)             (None, 16)                208       \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m  value_out (Dense)           (None, 1)                 17        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m Total params: 225\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m Trainable params: 225\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m Model: \"from_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m  ctx_input (InputLayer)      [(None, 16)]              0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m  from_logits (Dense)         (None, 3)                 51        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m Total params: 51\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m Trainable params: 51\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m Model: \"to_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m  from_input (InputLayer)     [(None, 3)]               0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m  to_hidden (Dense)           (None, 16)                64        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m  to_logits (Dense)           (None, 3)                 51        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m Total params: 115\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m Trainable params: 115\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m Metal device set to: Apple M1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m systemMemory: 16.00 GB\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m maxCacheSize: 5.33 GB\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m Model: \"base_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m  obs_input (InputLayer)      [(None, 3, 4)]            0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m  flatten (Flatten)           (None, 12)                0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m  context (Dense)             (None, 16)                208       \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m  value_out (Dense)           (None, 1)                 17        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m Total params: 225\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m Trainable params: 225\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m Model: \"from_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m  ctx_input (InputLayer)      [(None, 16)]              0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m  from_logits (Dense)         (None, 3)                 51        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m Total params: 51\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m Trainable params: 51\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m Metal device set to: Apple M1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m systemMemory: 16.00 GB\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m maxCacheSize: 5.33 GB\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m Model: \"base_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m  obs_input (InputLayer)      [(None, 3, 4)]            0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m  flatten (Flatten)           (None, 12)                0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m  context (Dense)             (None, 16)                208       \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m  value_out (Dense)           (None, 1)                 17        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m Total params: 225\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m Trainable params: 225\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m Model: \"from_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m  ctx_input (InputLayer)      [(None, 16)]              0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m  from_logits (Dense)         (None, 3)                 51        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m Total params: 51\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m Trainable params: 51\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m Model: \"to_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m  from_input (InputLayer)     [(None, 3)]               0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m  to_hidden (Dense)           (None, 16)                64        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m  to_logits (Dense)           (None, 3)                 51        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m Total params: 115\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m Trainable params: 115\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m Metal device set to: Apple M1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m systemMemory: 16.00 GB\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m maxCacheSize: 5.33 GB\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m Model: \"base_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m  obs_input (InputLayer)      [(None, 3, 4)]            0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m  flatten (Flatten)           (None, 12)                0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m  context (Dense)             (None, 16)                208       \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m  value_out (Dense)           (None, 1)                 17        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m Total params: 225\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m Trainable params: 225\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m Model: \"from_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m  ctx_input (InputLayer)      [(None, 16)]              0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m  from_logits (Dense)         (None, 3)                 51        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m Total params: 51\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m Trainable params: 51\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m Model: \"to_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m  from_input (InputLayer)     [(None, 3)]               0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m  to_hidden (Dense)           (None, 16)                64        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m  to_logits (Dense)           (None, 3)                 51        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m Total params: 115\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m Trainable params: 115\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m Model: \"base_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m  obs_input (InputLayer)      [(None, 3, 4)]            0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m  flatten (Flatten)           (None, 12)                0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m  context (Dense)             (None, 16)                208       \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m  value_out (Dense)           (None, 1)                 17        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m Total params: 225\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m Trainable params: 225\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m Model: \"from_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m  ctx_input (InputLayer)      [(None, 16)]              0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m  from_logits (Dense)         (None, 3)                 51        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m Total params: 51\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m Trainable params: 51\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m Model: \"to_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m  from_input (InputLayer)     [(None, 3)]               0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m  to_hidden (Dense)           (None, 16)                64        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m  to_logits (Dense)           (None, 3)                 51        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m Total params: 115\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m Trainable params: 115\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m Metal device set to: Apple M1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m systemMemory: 16.00 GB\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m maxCacheSize: 5.33 GB\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m Model: \"base_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m  obs_input (InputLayer)      [(None, 3, 4)]            0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m  flatten (Flatten)           (None, 12)                0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m  context (Dense)             (None, 16)                208       \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m  value_out (Dense)           (None, 1)                 17        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m Total params: 225\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m Trainable params: 225\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m Model: \"from_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m  ctx_input (InputLayer)      [(None, 16)]              0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m  from_logits (Dense)         (None, 3)                 51        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m Total params: 51\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m Trainable params: 51\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m Model: \"to_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m  from_input (InputLayer)     [(None, 3)]               0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m  to_hidden (Dense)           (None, 16)                64        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m  to_logits (Dense)           (None, 3)                 51        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m Total params: 115\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m Trainable params: 115\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m Model: \"to_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m  from_input (InputLayer)     [(None, 3)]               0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m  to_hidden (Dense)           (None, 16)                64        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m  to_logits (Dense)           (None, 3)                 51        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m Total params: 115\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m Trainable params: 115\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m Model: \"to_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m  from_input (InputLayer)     [(None, 3)]               0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m  to_hidden (Dense)           (None, 16)                64        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m  to_logits (Dense)           (None, 3)                 51        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m Total params: 115\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m Trainable params: 115\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m _________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m 2023-03-11 22:43:14,020\tERROR worker.py:772 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=29593, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x3049ef580>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 737, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m     self._build_policy_map(policy_dict=self.policy_dict)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1984, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m     new_policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/policy.py\", line 130, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m     return policy_class(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo_tf_policy.py\", line 83, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m     base.__init__(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 95, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m     ) = self._init_action_fetches(timestep, explore)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 624, in _init_action_fetches\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m     ) = self.exploration.get_exploration_action(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 84, in get_exploration_action\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m     return self._get_tf_exploration_action_op(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 91, in _get_tf_exploration_action_op\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m     stochastic_actions = tf.cond(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m     raise e.with_traceback(filtered_tb) from None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 94, in <lambda>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m     self.random_exploration.get_tf_exploration_action_op(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/random.py\", line 138, in get_tf_exploration_action_op\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m     action = tf.cond(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m ValueError: The two structures don't have the same nested structure.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m First structure: type=Tensor str=Tensor(\"default_policy_wk5/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m Second structure: type=tuple str=(<tf.Tensor 'default_policy_wk5/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk5/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m More specifically: Substructure \"type=tuple str=(<tf.Tensor 'default_policy_wk5/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk5/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\" is a sequence, while substructure \"type=Tensor str=Tensor(\"default_policy_wk5/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\" is not\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m Entire first structure:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m .\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m Entire second structure:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29593)\u001b[0m (., .)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m 2023-03-11 22:43:13,908\tWARNING env.py:156 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m 2023-03-11 22:43:13,908\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m 2023-03-11 22:43:14,028\tERROR worker.py:772 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=29589, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x30242b610>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 737, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m     self._build_policy_map(policy_dict=self.policy_dict)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1984, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m     new_policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/policy.py\", line 130, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m     return policy_class(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo_tf_policy.py\", line 83, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m     base.__init__(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 95, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m     ) = self._init_action_fetches(timestep, explore)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 624, in _init_action_fetches\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m     ) = self.exploration.get_exploration_action(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 84, in get_exploration_action\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m     return self._get_tf_exploration_action_op(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 91, in _get_tf_exploration_action_op\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m     stochastic_actions = tf.cond(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m     raise e.with_traceback(filtered_tb) from None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 94, in <lambda>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m     self.random_exploration.get_tf_exploration_action_op(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/random.py\", line 138, in get_tf_exploration_action_op\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m     action = tf.cond(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m ValueError: The two structures don't have the same nested structure.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m First structure: type=Tensor str=Tensor(\"default_policy_wk1/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m Second structure: type=tuple str=(<tf.Tensor 'default_policy_wk1/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk1/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m More specifically: Substructure \"type=tuple str=(<tf.Tensor 'default_policy_wk1/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk1/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\" is a sequence, while substructure \"type=Tensor str=Tensor(\"default_policy_wk1/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\" is not\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m Entire first structure:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m .\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m Entire second structure:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29589)\u001b[0m (., .)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m 2023-03-11 22:43:14,089\tERROR worker.py:772 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=29596, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x3057d36a0>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 737, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m     self._build_policy_map(policy_dict=self.policy_dict)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1984, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m     new_policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/policy.py\", line 130, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m     return policy_class(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo_tf_policy.py\", line 83, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m     base.__init__(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 95, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m     ) = self._init_action_fetches(timestep, explore)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 624, in _init_action_fetches\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m     ) = self.exploration.get_exploration_action(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 84, in get_exploration_action\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m     return self._get_tf_exploration_action_op(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 91, in _get_tf_exploration_action_op\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m     stochastic_actions = tf.cond(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m     raise e.with_traceback(filtered_tb) from None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 94, in <lambda>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m     self.random_exploration.get_tf_exploration_action_op(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/random.py\", line 138, in get_tf_exploration_action_op\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m     action = tf.cond(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m ValueError: The two structures don't have the same nested structure.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m First structure: type=Tensor str=Tensor(\"default_policy_wk8/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m Second structure: type=tuple str=(<tf.Tensor 'default_policy_wk8/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk8/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m More specifically: Substructure \"type=tuple str=(<tf.Tensor 'default_policy_wk8/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk8/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\" is a sequence, while substructure \"type=Tensor str=Tensor(\"default_policy_wk8/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\" is not\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m Entire first structure:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m .\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m Entire second structure:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29596)\u001b[0m (., .)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m 2023-03-11 22:43:14,042\tERROR worker.py:772 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=29592, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x30426f5e0>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 737, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m     self._build_policy_map(policy_dict=self.policy_dict)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1984, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m     new_policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/policy.py\", line 130, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m     return policy_class(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo_tf_policy.py\", line 83, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m     base.__init__(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 95, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m     ) = self._init_action_fetches(timestep, explore)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 624, in _init_action_fetches\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m     ) = self.exploration.get_exploration_action(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 84, in get_exploration_action\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m     return self._get_tf_exploration_action_op(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 91, in _get_tf_exploration_action_op\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m     stochastic_actions = tf.cond(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m     raise e.with_traceback(filtered_tb) from None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 94, in <lambda>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m     self.random_exploration.get_tf_exploration_action_op(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/random.py\", line 138, in get_tf_exploration_action_op\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m     action = tf.cond(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m ValueError: The two structures don't have the same nested structure.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m First structure: type=Tensor str=Tensor(\"default_policy_wk4/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m Second structure: type=tuple str=(<tf.Tensor 'default_policy_wk4/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk4/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m More specifically: Substructure \"type=tuple str=(<tf.Tensor 'default_policy_wk4/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk4/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\" is a sequence, while substructure \"type=Tensor str=Tensor(\"default_policy_wk4/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\" is not\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m Entire first structure:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m .\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m Entire second structure:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29592)\u001b[0m (., .)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m 2023-03-11 22:43:14,057\tERROR worker.py:772 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=29591, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x302def640>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 737, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m     self._build_policy_map(policy_dict=self.policy_dict)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1984, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m     new_policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/policy.py\", line 130, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m     return policy_class(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo_tf_policy.py\", line 83, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m     base.__init__(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 95, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m     ) = self._init_action_fetches(timestep, explore)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 624, in _init_action_fetches\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m     ) = self.exploration.get_exploration_action(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 84, in get_exploration_action\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m     return self._get_tf_exploration_action_op(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 91, in _get_tf_exploration_action_op\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m     stochastic_actions = tf.cond(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m     raise e.with_traceback(filtered_tb) from None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 94, in <lambda>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m     self.random_exploration.get_tf_exploration_action_op(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/random.py\", line 138, in get_tf_exploration_action_op\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m     action = tf.cond(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m ValueError: The two structures don't have the same nested structure.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m First structure: type=Tensor str=Tensor(\"default_policy_wk3/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m Second structure: type=tuple str=(<tf.Tensor 'default_policy_wk3/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk3/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m More specifically: Substructure \"type=tuple str=(<tf.Tensor 'default_policy_wk3/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk3/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\" is a sequence, while substructure \"type=Tensor str=Tensor(\"default_policy_wk3/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\" is not\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m Entire first structure:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m .\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m Entire second structure:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29591)\u001b[0m (., .)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m 2023-03-11 22:43:14,060\tERROR worker.py:772 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=29595, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x304d67610>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 737, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m     self._build_policy_map(policy_dict=self.policy_dict)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1984, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m     new_policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/policy.py\", line 130, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m     return policy_class(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo_tf_policy.py\", line 83, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m     base.__init__(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 95, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m     ) = self._init_action_fetches(timestep, explore)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 624, in _init_action_fetches\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m     ) = self.exploration.get_exploration_action(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 84, in get_exploration_action\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m     return self._get_tf_exploration_action_op(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 91, in _get_tf_exploration_action_op\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m     stochastic_actions = tf.cond(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m     raise e.with_traceback(filtered_tb) from None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 94, in <lambda>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m     self.random_exploration.get_tf_exploration_action_op(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/random.py\", line 138, in get_tf_exploration_action_op\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m     action = tf.cond(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m ValueError: The two structures don't have the same nested structure.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m First structure: type=Tensor str=Tensor(\"default_policy_wk7/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m Second structure: type=tuple str=(<tf.Tensor 'default_policy_wk7/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk7/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m More specifically: Substructure \"type=tuple str=(<tf.Tensor 'default_policy_wk7/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk7/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\" is a sequence, while substructure \"type=Tensor str=Tensor(\"default_policy_wk7/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\" is not\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m Entire first structure:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m .\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m Entire second structure:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29595)\u001b[0m (., .)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m 2023-03-11 22:43:14,079\tERROR worker.py:772 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=29594, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x3068ef5e0>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 737, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m     self._build_policy_map(policy_dict=self.policy_dict)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1984, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m     new_policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/policy.py\", line 130, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m     return policy_class(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo_tf_policy.py\", line 83, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m     base.__init__(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 95, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m     ) = self._init_action_fetches(timestep, explore)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 624, in _init_action_fetches\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m     ) = self.exploration.get_exploration_action(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 84, in get_exploration_action\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m     return self._get_tf_exploration_action_op(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 91, in _get_tf_exploration_action_op\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m     stochastic_actions = tf.cond(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m     raise e.with_traceback(filtered_tb) from None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 94, in <lambda>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m     self.random_exploration.get_tf_exploration_action_op(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/random.py\", line 138, in get_tf_exploration_action_op\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m     action = tf.cond(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m ValueError: The two structures don't have the same nested structure.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m First structure: type=Tensor str=Tensor(\"default_policy_wk6/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m Second structure: type=tuple str=(<tf.Tensor 'default_policy_wk6/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk6/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m More specifically: Substructure \"type=tuple str=(<tf.Tensor 'default_policy_wk6/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk6/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\" is a sequence, while substructure \"type=Tensor str=Tensor(\"default_policy_wk6/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\" is not\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m Entire first structure:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m .\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m Entire second structure:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29594)\u001b[0m (., .)\n",
      "2023-03-11 22:43:14,199\tERROR actor_manager.py:496 -- Ray error, taking actor 1 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=29589, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x30242b610>)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 737, in __init__\n",
      "    self._build_policy_map(policy_dict=self.policy_dict)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1984, in _build_policy_map\n",
      "    new_policy = create_policy_for_framework(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/policy.py\", line 130, in create_policy_for_framework\n",
      "    return policy_class(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo_tf_policy.py\", line 83, in __init__\n",
      "    base.__init__(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 95, in __init__\n",
      "    ) = self._init_action_fetches(timestep, explore)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 624, in _init_action_fetches\n",
      "    ) = self.exploration.get_exploration_action(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 84, in get_exploration_action\n",
      "    return self._get_tf_exploration_action_op(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 91, in _get_tf_exploration_action_op\n",
      "    stochastic_actions = tf.cond(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 94, in <lambda>\n",
      "    self.random_exploration.get_tf_exploration_action_op(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/random.py\", line 138, in get_tf_exploration_action_op\n",
      "    action = tf.cond(\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=Tensor str=Tensor(\"default_policy_wk1/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\n",
      "\n",
      "Second structure: type=tuple str=(<tf.Tensor 'default_policy_wk1/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk1/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\n",
      "\n",
      "More specifically: Substructure \"type=tuple str=(<tf.Tensor 'default_policy_wk1/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk1/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\" is a sequence, while substructure \"type=Tensor str=Tensor(\"default_policy_wk1/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\" is not\n",
      "Entire first structure:\n",
      ".\n",
      "Entire second structure:\n",
      "(., .)\n",
      "2023-03-11 22:43:14,200\tERROR actor_manager.py:496 -- Ray error, taking actor 2 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=29590, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x16c1eb670>)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 737, in __init__\n",
      "    self._build_policy_map(policy_dict=self.policy_dict)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1984, in _build_policy_map\n",
      "    new_policy = create_policy_for_framework(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/policy.py\", line 130, in create_policy_for_framework\n",
      "    return policy_class(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo_tf_policy.py\", line 83, in __init__\n",
      "    base.__init__(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 95, in __init__\n",
      "    ) = self._init_action_fetches(timestep, explore)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 624, in _init_action_fetches\n",
      "    ) = self.exploration.get_exploration_action(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 84, in get_exploration_action\n",
      "    return self._get_tf_exploration_action_op(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 91, in _get_tf_exploration_action_op\n",
      "    stochastic_actions = tf.cond(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 94, in <lambda>\n",
      "    self.random_exploration.get_tf_exploration_action_op(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/random.py\", line 138, in get_tf_exploration_action_op\n",
      "    action = tf.cond(\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=Tensor str=Tensor(\"default_policy_wk2/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\n",
      "\n",
      "Second structure: type=tuple str=(<tf.Tensor 'default_policy_wk2/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk2/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\n",
      "\n",
      "More specifically: Substructure \"type=tuple str=(<tf.Tensor 'default_policy_wk2/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk2/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\" is a sequence, while substructure \"type=Tensor str=Tensor(\"default_policy_wk2/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\" is not\n",
      "Entire first structure:\n",
      ".\n",
      "Entire second structure:\n",
      "(., .)\n",
      "2023-03-11 22:43:14,200\tERROR actor_manager.py:496 -- Ray error, taking actor 3 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=29591, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x302def640>)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 737, in __init__\n",
      "    self._build_policy_map(policy_dict=self.policy_dict)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1984, in _build_policy_map\n",
      "    new_policy = create_policy_for_framework(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/policy.py\", line 130, in create_policy_for_framework\n",
      "    return policy_class(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo_tf_policy.py\", line 83, in __init__\n",
      "    base.__init__(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 95, in __init__\n",
      "    ) = self._init_action_fetches(timestep, explore)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 624, in _init_action_fetches\n",
      "    ) = self.exploration.get_exploration_action(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 84, in get_exploration_action\n",
      "    return self._get_tf_exploration_action_op(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 91, in _get_tf_exploration_action_op\n",
      "    stochastic_actions = tf.cond(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 94, in <lambda>\n",
      "    self.random_exploration.get_tf_exploration_action_op(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/random.py\", line 138, in get_tf_exploration_action_op\n",
      "    action = tf.cond(\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=Tensor str=Tensor(\"default_policy_wk3/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\n",
      "\n",
      "Second structure: type=tuple str=(<tf.Tensor 'default_policy_wk3/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk3/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\n",
      "\n",
      "More specifically: Substructure \"type=tuple str=(<tf.Tensor 'default_policy_wk3/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk3/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\" is a sequence, while substructure \"type=Tensor str=Tensor(\"default_policy_wk3/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\" is not\n",
      "Entire first structure:\n",
      ".\n",
      "Entire second structure:\n",
      "(., .)\n",
      "2023-03-11 22:43:14,201\tERROR actor_manager.py:496 -- Ray error, taking actor 4 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=29592, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x30426f5e0>)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 737, in __init__\n",
      "    self._build_policy_map(policy_dict=self.policy_dict)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1984, in _build_policy_map\n",
      "    new_policy = create_policy_for_framework(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/policy.py\", line 130, in create_policy_for_framework\n",
      "    return policy_class(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo_tf_policy.py\", line 83, in __init__\n",
      "    base.__init__(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 95, in __init__\n",
      "    ) = self._init_action_fetches(timestep, explore)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 624, in _init_action_fetches\n",
      "    ) = self.exploration.get_exploration_action(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 84, in get_exploration_action\n",
      "    return self._get_tf_exploration_action_op(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 91, in _get_tf_exploration_action_op\n",
      "    stochastic_actions = tf.cond(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 94, in <lambda>\n",
      "    self.random_exploration.get_tf_exploration_action_op(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/random.py\", line 138, in get_tf_exploration_action_op\n",
      "    action = tf.cond(\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=Tensor str=Tensor(\"default_policy_wk4/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\n",
      "\n",
      "Second structure: type=tuple str=(<tf.Tensor 'default_policy_wk4/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk4/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\n",
      "\n",
      "More specifically: Substructure \"type=tuple str=(<tf.Tensor 'default_policy_wk4/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk4/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\" is a sequence, while substructure \"type=Tensor str=Tensor(\"default_policy_wk4/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\" is not\n",
      "Entire first structure:\n",
      ".\n",
      "Entire second structure:\n",
      "(., .)\n",
      "2023-03-11 22:43:14,201\tERROR actor_manager.py:496 -- Ray error, taking actor 5 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=29593, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x3049ef580>)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 737, in __init__\n",
      "    self._build_policy_map(policy_dict=self.policy_dict)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1984, in _build_policy_map\n",
      "    new_policy = create_policy_for_framework(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/policy.py\", line 130, in create_policy_for_framework\n",
      "    return policy_class(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo_tf_policy.py\", line 83, in __init__\n",
      "    base.__init__(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 95, in __init__\n",
      "    ) = self._init_action_fetches(timestep, explore)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 624, in _init_action_fetches\n",
      "    ) = self.exploration.get_exploration_action(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 84, in get_exploration_action\n",
      "    return self._get_tf_exploration_action_op(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 91, in _get_tf_exploration_action_op\n",
      "    stochastic_actions = tf.cond(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 94, in <lambda>\n",
      "    self.random_exploration.get_tf_exploration_action_op(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/random.py\", line 138, in get_tf_exploration_action_op\n",
      "    action = tf.cond(\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=Tensor str=Tensor(\"default_policy_wk5/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\n",
      "\n",
      "Second structure: type=tuple str=(<tf.Tensor 'default_policy_wk5/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk5/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\n",
      "\n",
      "More specifically: Substructure \"type=tuple str=(<tf.Tensor 'default_policy_wk5/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk5/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\" is a sequence, while substructure \"type=Tensor str=Tensor(\"default_policy_wk5/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\" is not\n",
      "Entire first structure:\n",
      ".\n",
      "Entire second structure:\n",
      "(., .)\n",
      "2023-03-11 22:43:14,201\tERROR actor_manager.py:496 -- Ray error, taking actor 6 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=29594, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x3068ef5e0>)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 737, in __init__\n",
      "    self._build_policy_map(policy_dict=self.policy_dict)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1984, in _build_policy_map\n",
      "    new_policy = create_policy_for_framework(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/policy.py\", line 130, in create_policy_for_framework\n",
      "    return policy_class(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo_tf_policy.py\", line 83, in __init__\n",
      "    base.__init__(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 95, in __init__\n",
      "    ) = self._init_action_fetches(timestep, explore)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 624, in _init_action_fetches\n",
      "    ) = self.exploration.get_exploration_action(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 84, in get_exploration_action\n",
      "    return self._get_tf_exploration_action_op(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 91, in _get_tf_exploration_action_op\n",
      "    stochastic_actions = tf.cond(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 94, in <lambda>\n",
      "    self.random_exploration.get_tf_exploration_action_op(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/random.py\", line 138, in get_tf_exploration_action_op\n",
      "    action = tf.cond(\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=Tensor str=Tensor(\"default_policy_wk6/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\n",
      "\n",
      "Second structure: type=tuple str=(<tf.Tensor 'default_policy_wk6/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk6/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\n",
      "\n",
      "More specifically: Substructure \"type=tuple str=(<tf.Tensor 'default_policy_wk6/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk6/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\" is a sequence, while substructure \"type=Tensor str=Tensor(\"default_policy_wk6/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\" is not\n",
      "Entire first structure:\n",
      ".\n",
      "Entire second structure:\n",
      "(., .)\n",
      "2023-03-11 22:43:14,202\tERROR actor_manager.py:496 -- Ray error, taking actor 7 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=29595, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x304d67610>)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 737, in __init__\n",
      "    self._build_policy_map(policy_dict=self.policy_dict)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1984, in _build_policy_map\n",
      "    new_policy = create_policy_for_framework(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/policy.py\", line 130, in create_policy_for_framework\n",
      "    return policy_class(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo_tf_policy.py\", line 83, in __init__\n",
      "    base.__init__(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 95, in __init__\n",
      "    ) = self._init_action_fetches(timestep, explore)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 624, in _init_action_fetches\n",
      "    ) = self.exploration.get_exploration_action(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 84, in get_exploration_action\n",
      "    return self._get_tf_exploration_action_op(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 91, in _get_tf_exploration_action_op\n",
      "    stochastic_actions = tf.cond(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 94, in <lambda>\n",
      "    self.random_exploration.get_tf_exploration_action_op(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/random.py\", line 138, in get_tf_exploration_action_op\n",
      "    action = tf.cond(\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=Tensor str=Tensor(\"default_policy_wk7/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\n",
      "\n",
      "Second structure: type=tuple str=(<tf.Tensor 'default_policy_wk7/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk7/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\n",
      "\n",
      "More specifically: Substructure \"type=tuple str=(<tf.Tensor 'default_policy_wk7/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk7/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\" is a sequence, while substructure \"type=Tensor str=Tensor(\"default_policy_wk7/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\" is not\n",
      "Entire first structure:\n",
      ".\n",
      "Entire second structure:\n",
      "(., .)\n",
      "2023-03-11 22:43:14,202\tERROR actor_manager.py:496 -- Ray error, taking actor 8 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=29596, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x3057d36a0>)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 737, in __init__\n",
      "    self._build_policy_map(policy_dict=self.policy_dict)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1984, in _build_policy_map\n",
      "    new_policy = create_policy_for_framework(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/policy.py\", line 130, in create_policy_for_framework\n",
      "    return policy_class(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo_tf_policy.py\", line 83, in __init__\n",
      "    base.__init__(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 95, in __init__\n",
      "    ) = self._init_action_fetches(timestep, explore)\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 624, in _init_action_fetches\n",
      "    ) = self.exploration.get_exploration_action(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 84, in get_exploration_action\n",
      "    return self._get_tf_exploration_action_op(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 91, in _get_tf_exploration_action_op\n",
      "    stochastic_actions = tf.cond(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 94, in <lambda>\n",
      "    self.random_exploration.get_tf_exploration_action_op(\n",
      "  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/random.py\", line 138, in get_tf_exploration_action_op\n",
      "    action = tf.cond(\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=Tensor str=Tensor(\"default_policy_wk8/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\n",
      "\n",
      "Second structure: type=tuple str=(<tf.Tensor 'default_policy_wk8/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk8/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\n",
      "\n",
      "More specifically: Substructure \"type=tuple str=(<tf.Tensor 'default_policy_wk8/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk8/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\" is a sequence, while substructure \"type=Tensor str=Tensor(\"default_policy_wk8/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\" is not\n",
      "Entire first structure:\n",
      ".\n",
      "Entire second structure:\n",
      "(., .)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m Metal device set to: Apple M1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m systemMemory: 16.00 GB\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m maxCacheSize: 5.33 GB\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m Model: \"base_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m  obs_input (InputLayer)      [(None, 3, 4)]            0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m  flatten (Flatten)           (None, 12)                0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m  context (Dense)             (None, 16)                208       \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m  value_out (Dense)           (None, 1)                 17        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m Total params: 225\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m Trainable params: 225\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m Model: \"from_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m  ctx_input (InputLayer)      [(None, 16)]              0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m  from_logits (Dense)         (None, 3)                 51        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m Total params: 51\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m Trainable params: 51\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m Model: \"to_model\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m  from_input (InputLayer)     [(None, 3)]               0         \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m  to_hidden (Dense)           (None, 16)                64        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m  to_logits (Dense)           (None, 3)                 51        \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m                                                                  \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m Total params: 115\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m Trainable params: 115\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m _________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m 2023-03-11 22:43:14,197\tERROR worker.py:772 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=29590, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x16c1eb670>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 737, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m     self._build_policy_map(policy_dict=self.policy_dict)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1984, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m     new_policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/policy.py\", line 130, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m     return policy_class(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo_tf_policy.py\", line 83, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m     base.__init__(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 95, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m     ) = self._init_action_fetches(timestep, explore)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 624, in _init_action_fetches\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m     ) = self.exploration.get_exploration_action(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 84, in get_exploration_action\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m     return self._get_tf_exploration_action_op(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 91, in _get_tf_exploration_action_op\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m     stochastic_actions = tf.cond(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m     raise e.with_traceback(filtered_tb) from None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 94, in <lambda>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m     self.random_exploration.get_tf_exploration_action_op(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m   File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/random.py\", line 138, in get_tf_exploration_action_op\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m     action = tf.cond(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m ValueError: The two structures don't have the same nested structure.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m First structure: type=Tensor str=Tensor(\"default_policy_wk2/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m Second structure: type=tuple str=(<tf.Tensor 'default_policy_wk2/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk2/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m More specifically: Substructure \"type=tuple str=(<tf.Tensor 'default_policy_wk2/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk2/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\" is a sequence, while substructure \"type=Tensor str=Tensor(\"default_policy_wk2/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\" is not\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m Entire first structure:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m .\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m Entire second structure:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=29590)\u001b[0m (., .)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The two structures don't have the same nested structure.\n\nFirst structure: type=Tensor str=Tensor(\"default_policy_wk1/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\n\nSecond structure: type=tuple str=(<tf.Tensor 'default_policy_wk1/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk1/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\n\nMore specifically: Substructure \"type=tuple str=(<tf.Tensor 'default_policy_wk1/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk1/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\" is a sequence, while substructure \"type=Tensor str=Tensor(\"default_policy_wk1/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\" is not\nEntire first structure:\n.\nEntire second structure:\n(., .)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayActorError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py:170\u001b[0m, in \u001b[0;36mWorkerSet.__init__\u001b[0;34m(self, env_creator, validate_env, default_policy_class, config, num_workers, local_worker, logdir, _setup, policy_class, trainer_config)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup(\n\u001b[1;32m    171\u001b[0m         validate_env\u001b[39m=\u001b[39;49mvalidate_env,\n\u001b[1;32m    172\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    173\u001b[0m         num_workers\u001b[39m=\u001b[39;49mnum_workers,\n\u001b[1;32m    174\u001b[0m         local_worker\u001b[39m=\u001b[39;49mlocal_worker,\n\u001b[1;32m    175\u001b[0m     )\n\u001b[1;32m    176\u001b[0m \u001b[39m# WorkerSet creation possibly fails, if some (remote) workers cannot\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[39m# be initialized properly (due to some errors in the RolloutWorker's\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[39m# constructor).\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py:240\u001b[0m, in \u001b[0;36mWorkerSet._setup\u001b[0;34m(self, validate_env, config, num_workers, local_worker)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[39m# Create a number of @ray.remote workers.\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_workers(\n\u001b[1;32m    241\u001b[0m     num_workers,\n\u001b[1;32m    242\u001b[0m     validate\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mvalidate_workers_after_construction,\n\u001b[1;32m    243\u001b[0m )\n\u001b[1;32m    245\u001b[0m \u001b[39m# If num_workers > 0 and we don't have an env on the local worker,\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[39m# get the observation- and action spaces for each policy from\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[39m# the first remote worker (which does have an env).\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py:614\u001b[0m, in \u001b[0;36mWorkerSet.add_workers\u001b[0;34m(self, num_workers, validate)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39mok:\n\u001b[0;32m--> 614\u001b[0m     \u001b[39mraise\u001b[39;00m result\u001b[39m.\u001b[39mget()\n",
      "File \u001b[0;32m~/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/actor_manager.py:477\u001b[0m, in \u001b[0;36mFaultTolerantActorManager.__fetch_result\u001b[0;34m(self, remote_actor_ids, remote_calls, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 477\u001b[0m     result \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39;49mget(r)\n\u001b[1;32m    478\u001b[0m     remote_results\u001b[39m.\u001b[39madd_result(actor_id, ResultOrError(result\u001b[39m=\u001b[39mresult))\n",
      "File \u001b[0;32m~/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(ray, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 105\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/_private/worker.py:2382\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2381\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2382\u001b[0m             \u001b[39mraise\u001b[39;00m value\n\u001b[1;32m   2384\u001b[0m \u001b[39mif\u001b[39;00m is_individual_id:\n",
      "\u001b[0;31mRayActorError\u001b[0m: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=29589, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x30242b610>)\n  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 737, in __init__\n    self._build_policy_map(policy_dict=self.policy_dict)\n  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1984, in _build_policy_map\n    new_policy = create_policy_for_framework(\n  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/policy.py\", line 130, in create_policy_for_framework\n    return policy_class(\n  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo_tf_policy.py\", line 83, in __init__\n    base.__init__(\n  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 95, in __init__\n    ) = self._init_action_fetches(timestep, explore)\n  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/dynamic_tf_policy_v2.py\", line 624, in _init_action_fetches\n    ) = self.exploration.get_exploration_action(\n  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 84, in get_exploration_action\n    return self._get_tf_exploration_action_op(\n  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 91, in _get_tf_exploration_action_op\n    stochastic_actions = tf.cond(\n  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/stochastic_sampling.py\", line 94, in <lambda>\n    self.random_exploration.get_tf_exploration_action_op(\n  File \"/Users/abdulhakeemabdulrahman/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/exploration/random.py\", line 138, in get_tf_exploration_action_op\n    action = tf.cond(\nValueError: The two structures don't have the same nested structure.\n\nFirst structure: type=Tensor str=Tensor(\"default_policy_wk1/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\n\nSecond structure: type=tuple str=(<tf.Tensor 'default_policy_wk1/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk1/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\n\nMore specifically: Substructure \"type=tuple str=(<tf.Tensor 'default_policy_wk1/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk1/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\" is a sequence, while substructure \"type=Tensor str=Tensor(\"default_policy_wk1/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\" is not\nEntire first structure:\n.\nEntire second structure:\n(., .)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 40\u001b[0m\n\u001b[1;32m     32\u001b[0m config\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mupdate({\n\u001b[1;32m     33\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcustom_model\u001b[39m\u001b[39m'\u001b[39m: MODEL_NAME,\n\u001b[1;32m     34\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcustom_model_config\u001b[39m\u001b[39m'\u001b[39m: model_config,\n\u001b[1;32m     35\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcustom_action_dist\u001b[39m\u001b[39m'\u001b[39m: ACTION_DIST_NAME,\n\u001b[1;32m     36\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mvf_share_layers\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     37\u001b[0m })\n\u001b[1;32m     39\u001b[0m config\u001b[39m.\u001b[39mseed \u001b[39m=\u001b[39m \u001b[39m19\u001b[39m\n\u001b[0;32m---> 40\u001b[0m agent \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39;49mbuild()\n",
      "File \u001b[0;32m~/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm_config.py:926\u001b[0m, in \u001b[0;36mAlgorithmConfig.build\u001b[0;34m(self, env, logger_creator, use_copy)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgo_class, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    924\u001b[0m     algo_class \u001b[39m=\u001b[39m get_trainable_cls(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgo_class)\n\u001b[0;32m--> 926\u001b[0m \u001b[39mreturn\u001b[39;00m algo_class(\n\u001b[1;32m    927\u001b[0m     config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m use_copy \u001b[39melse\u001b[39;49;00m copy\u001b[39m.\u001b[39;49mdeepcopy(\u001b[39mself\u001b[39;49m),\n\u001b[1;32m    928\u001b[0m     logger_creator\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlogger_creator,\n\u001b[1;32m    929\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:445\u001b[0m, in \u001b[0;36mAlgorithm.__init__\u001b[0;34m(self, config, env, logger_creator, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39m# Initialize common evaluation_metrics to nan, before they become\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[39m# available. We want to make sure the metrics are always present\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m# (although their values may be nan), so that Tune does not complain\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[39m# when we use these as stopping criteria.\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_metrics \u001b[39m=\u001b[39m {\n\u001b[1;32m    438\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mevaluation\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[1;32m    439\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mepisode_reward_max\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39mnan,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    442\u001b[0m     }\n\u001b[1;32m    443\u001b[0m }\n\u001b[0;32m--> 445\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    446\u001b[0m     config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    447\u001b[0m     logger_creator\u001b[39m=\u001b[39;49mlogger_creator,\n\u001b[1;32m    448\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    449\u001b[0m )\n\u001b[1;32m    451\u001b[0m \u001b[39m# Check, whether `training_iteration` is still a tune.Trainable property\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39m# and has not been overridden by the user in the attempt to implement the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39m# algos logic (this should be done now inside `training_step`).\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/tune/trainable/trainable.py:169\u001b[0m, in \u001b[0;36mTrainable.__init__\u001b[0;34m(self, config, logger_creator, remote_checkpoint_dir, custom_syncer, sync_timeout)\u001b[0m\n\u001b[1;32m    167\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    168\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_ip \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39mutil\u001b[39m.\u001b[39mget_node_ip_address()\n\u001b[0;32m--> 169\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup(copy\u001b[39m.\u001b[39;49mdeepcopy(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig))\n\u001b[1;32m    170\u001b[0m setup_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m setup_time \u001b[39m>\u001b[39m SETUP_TIME_THRESHOLD:\n",
      "File \u001b[0;32m~/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:571\u001b[0m, in \u001b[0;36mAlgorithm.setup\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m# Only if user did not override `_init()`:\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mif\u001b[39;00m _init \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    566\u001b[0m     \u001b[39m# - Create rollout workers here automatically.\u001b[39;00m\n\u001b[1;32m    567\u001b[0m     \u001b[39m# - Run the execution plan to create the local iterator to `next()`\u001b[39;00m\n\u001b[1;32m    568\u001b[0m     \u001b[39m#   in each training iteration.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m     \u001b[39m# This matches the behavior of using `build_trainer()`, which\u001b[39;00m\n\u001b[1;32m    570\u001b[0m     \u001b[39m# has been deprecated.\u001b[39;00m\n\u001b[0;32m--> 571\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers \u001b[39m=\u001b[39m WorkerSet(\n\u001b[1;32m    572\u001b[0m         env_creator\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv_creator,\n\u001b[1;32m    573\u001b[0m         validate_env\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalidate_env,\n\u001b[1;32m    574\u001b[0m         default_policy_class\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_default_policy_class(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig),\n\u001b[1;32m    575\u001b[0m         config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig,\n\u001b[1;32m    576\u001b[0m         num_workers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnum_rollout_workers,\n\u001b[1;32m    577\u001b[0m         local_worker\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    578\u001b[0m         logdir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlogdir,\n\u001b[1;32m    579\u001b[0m     )\n\u001b[1;32m    581\u001b[0m     \u001b[39m# TODO (avnishn): Remove the execution plan API by q1 2023\u001b[39;00m\n\u001b[1;32m    582\u001b[0m     \u001b[39m# Function defining one single training iteration's behavior.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_disable_execution_plan_api:\n\u001b[1;32m    584\u001b[0m         \u001b[39m# Ensure remote workers are initially in sync with the local worker.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py:192\u001b[0m, in \u001b[0;36mWorkerSet.__init__\u001b[0;34m(self, env_creator, validate_env, default_policy_class, config, num_workers, local_worker, logdir, _setup, policy_class, trainer_config)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39mexcept\u001b[39;00m RayActorError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     \u001b[39m# In case of an actor (remote worker) init failure, the remote worker\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[39m# may still exist and will be accessible, however, e.g. calling\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[39m# its `sample.remote()` would result in strange \"property not found\"\u001b[39;00m\n\u001b[1;32m    183\u001b[0m     \u001b[39m# errors.\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39mactor_init_failed:\n\u001b[1;32m    185\u001b[0m         \u001b[39m# Raise the original error here that the RolloutWorker raised\u001b[39;00m\n\u001b[1;32m    186\u001b[0m         \u001b[39m# during its construction process. This is to enforce transparency\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[39m# - e.args[0].args[2]: The original Exception (e.g. a ValueError due\u001b[39;00m\n\u001b[1;32m    191\u001b[0m         \u001b[39m# to a config mismatch) thrown inside the actor.\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m         \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39margs[\u001b[39m2\u001b[39m]\n\u001b[1;32m    193\u001b[0m     \u001b[39m# In any other case, raise the RayActorError as-is.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m         \u001b[39mraise\u001b[39;00m e\n",
      "\u001b[0;31mValueError\u001b[0m: The two structures don't have the same nested structure.\n\nFirst structure: type=Tensor str=Tensor(\"default_policy_wk1/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\n\nSecond structure: type=tuple str=(<tf.Tensor 'default_policy_wk1/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk1/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\n\nMore specifically: Substructure \"type=tuple str=(<tf.Tensor 'default_policy_wk1/cond/cond/ArgMax:0' shape=(?,) dtype=int64>, <tf.Tensor 'default_policy_wk1/cond/cond/ArgMax_1:0' shape=(?,) dtype=int64>)\" is a sequence, while substructure \"type=Tensor str=Tensor(\"default_policy_wk1/cond/cond/concat:0\", shape=(?, 2), dtype=int64)\" is not\nEntire first structure:\n.\nEntire second structure:\n(., .)"
     ]
    }
   ],
   "source": [
    "n_disks = 4\n",
    "env_config = {\n",
    "    'n_disks': n_disks,\n",
    "    'max_n_steps': 10000 #2 ** (n_disks + 2)\n",
    "}\n",
    "\n",
    "def create_env(config):\n",
    "    _env = HanoiTower(config)\n",
    "    _env = PreprocessorEnv(_env)\n",
    "    return _env\n",
    "\n",
    "ENV_NAME = 'hanoi_tower'\n",
    "register_env(ENV_NAME, create_env)\n",
    "\n",
    "config = ppo.PPOConfig()\n",
    "config = config.training(lr=1e-3,\n",
    "                         gamma=0.9,\n",
    "                         train_batch_size=512 * 2,\n",
    "                         sgd_minibatch_size=256 * 1,\n",
    "                         num_sgd_iter=16 * 1)\n",
    "config = config.rollouts(num_rollout_workers=8,\n",
    "                         num_envs_per_worker=4)\n",
    "config = config.environment(ENV_NAME, \n",
    "                            env_config=env_config)\n",
    "config = config.resources(num_gpus=1)\n",
    "config = config.framework('tf')\n",
    "\n",
    "model_config = {\n",
    "    'n_hiddens': 16\n",
    "}\n",
    "\n",
    "config.model.update({\n",
    "    'custom_model': MODEL_NAME,\n",
    "    'custom_model_config': model_config,\n",
    "    'custom_action_dist': ACTION_DIST_NAME,\n",
    "    'vf_share_layers': True\n",
    "})\n",
    "\n",
    "config.seed = 19\n",
    "agent = config.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'extra_python_environs_for_driver': {},\n",
       " 'extra_python_environs_for_worker': {},\n",
       " 'num_gpus': 1,\n",
       " 'num_cpus_per_worker': 1,\n",
       " 'num_gpus_per_worker': 0,\n",
       " '_fake_gpus': False,\n",
       " 'num_trainer_workers': 0,\n",
       " 'num_gpus_per_trainer_worker': 0,\n",
       " 'num_cpus_per_trainer_worker': 1,\n",
       " 'custom_resources_per_worker': {},\n",
       " 'placement_strategy': 'PACK',\n",
       " 'eager_tracing': False,\n",
       " 'eager_max_retraces': 20,\n",
       " 'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "  'inter_op_parallelism_threads': 2,\n",
       "  'gpu_options': {'allow_growth': True},\n",
       "  'log_device_placement': False,\n",
       "  'device_count': {'CPU': 1},\n",
       "  'allow_soft_placement': True},\n",
       " 'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "  'inter_op_parallelism_threads': 8},\n",
       " 'env': 'hanoi_tower',\n",
       " 'env_config': {'n_disks': 4, 'max_n_steps': 10000},\n",
       " 'observation_space': None,\n",
       " 'action_space': None,\n",
       " 'env_task_fn': None,\n",
       " 'render_env': False,\n",
       " 'clip_rewards': None,\n",
       " 'normalize_actions': True,\n",
       " 'clip_actions': False,\n",
       " 'disable_env_checking': False,\n",
       " 'is_atari': None,\n",
       " 'auto_wrap_old_gym_envs': True,\n",
       " 'num_envs_per_worker': 4,\n",
       " 'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       " 'sample_async': False,\n",
       " 'enable_connectors': True,\n",
       " 'rollout_fragment_length': 'auto',\n",
       " 'batch_mode': 'truncate_episodes',\n",
       " 'remote_worker_envs': False,\n",
       " 'remote_env_batch_wait_ms': 0,\n",
       " 'validate_workers_after_construction': True,\n",
       " 'ignore_worker_failures': False,\n",
       " 'recreate_failed_workers': False,\n",
       " 'restart_failed_sub_environments': False,\n",
       " 'num_consecutive_worker_failures_tolerance': 100,\n",
       " 'preprocessor_pref': 'deepmind',\n",
       " 'observation_filter': 'NoFilter',\n",
       " 'synchronize_filters': True,\n",
       " 'compress_observations': False,\n",
       " 'enable_tf1_exec_eagerly': False,\n",
       " 'sampler_perf_stats_ema_coef': None,\n",
       " 'worker_health_probe_timeout_s': 60,\n",
       " 'worker_restore_timeout_s': 1800,\n",
       " 'gamma': 0.9,\n",
       " 'lr': 0.001,\n",
       " 'train_batch_size': 1024,\n",
       " 'model': {'_disable_preprocessor_api': False,\n",
       "  '_disable_action_flattening': False,\n",
       "  'fcnet_hiddens': [256, 256],\n",
       "  'fcnet_activation': 'tanh',\n",
       "  'conv_filters': None,\n",
       "  'conv_activation': 'relu',\n",
       "  'post_fcnet_hiddens': [],\n",
       "  'post_fcnet_activation': 'relu',\n",
       "  'free_log_std': False,\n",
       "  'no_final_linear': False,\n",
       "  'vf_share_layers': False,\n",
       "  'use_lstm': False,\n",
       "  'max_seq_len': 20,\n",
       "  'lstm_cell_size': 256,\n",
       "  'lstm_use_prev_action': False,\n",
       "  'lstm_use_prev_reward': False,\n",
       "  '_time_major': False,\n",
       "  'use_attention': False,\n",
       "  'attention_num_transformer_units': 1,\n",
       "  'attention_dim': 64,\n",
       "  'attention_num_heads': 1,\n",
       "  'attention_head_dim': 32,\n",
       "  'attention_memory_inference': 50,\n",
       "  'attention_memory_training': 50,\n",
       "  'attention_position_wise_mlp_dim': 32,\n",
       "  'attention_init_gru_gate_bias': 2.0,\n",
       "  'attention_use_n_prev_actions': 0,\n",
       "  'attention_use_n_prev_rewards': 0,\n",
       "  'framestack': True,\n",
       "  'dim': 84,\n",
       "  'grayscale': False,\n",
       "  'zero_mean': True,\n",
       "  'custom_model': None,\n",
       "  'custom_model_config': {},\n",
       "  'custom_action_dist': None,\n",
       "  'custom_preprocessor': None,\n",
       "  'lstm_use_prev_action_reward': -1,\n",
       "  '_use_default_native_models': -1},\n",
       " 'optimizer': {},\n",
       " 'max_requests_in_flight_per_sampler_worker': 2,\n",
       " 'rl_trainer_class': None,\n",
       " '_enable_rl_trainer_api': False,\n",
       " '_rl_trainer_hps': RLTrainerHPs(),\n",
       " 'explore': True,\n",
       " 'exploration_config': {'type': 'StochasticSampling'},\n",
       " 'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec at 0x2a57542b0>},\n",
       " 'policy_states_are_swappable': False,\n",
       " 'input_config': {},\n",
       " 'actions_in_input_normalized': False,\n",
       " 'postprocess_inputs': False,\n",
       " 'shuffle_buffer_size': 0,\n",
       " 'output': None,\n",
       " 'output_config': {},\n",
       " 'output_compress_columns': ['obs', 'new_obs'],\n",
       " 'output_max_file_size': 67108864,\n",
       " 'offline_sampling': False,\n",
       " 'evaluation_interval': None,\n",
       " 'evaluation_duration': 10,\n",
       " 'evaluation_duration_unit': 'episodes',\n",
       " 'evaluation_sample_timeout_s': 180.0,\n",
       " 'evaluation_parallel_to_training': False,\n",
       " 'evaluation_config': None,\n",
       " 'off_policy_estimation_methods': {},\n",
       " 'ope_split_batch_by_episode': True,\n",
       " 'evaluation_num_workers': 0,\n",
       " 'always_attach_evaluation_results': False,\n",
       " 'enable_async_evaluation': False,\n",
       " 'in_evaluation': False,\n",
       " 'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
       " 'keep_per_episode_custom_metrics': False,\n",
       " 'metrics_episode_collection_timeout_s': 60.0,\n",
       " 'metrics_num_episodes_for_smoothing': 100,\n",
       " 'min_time_s_per_iteration': None,\n",
       " 'min_train_timesteps_per_iteration': 0,\n",
       " 'min_sample_timesteps_per_iteration': 0,\n",
       " 'export_native_model_files': False,\n",
       " 'checkpoint_trainable_policies_only': False,\n",
       " 'logger_creator': None,\n",
       " 'logger_config': None,\n",
       " 'log_level': 'WARN',\n",
       " 'log_sys_usage': True,\n",
       " 'fake_sampler': False,\n",
       " 'seed': 19,\n",
       " 'worker_cls': None,\n",
       " 'rl_module_class': None,\n",
       " '_enable_rl_module_api': False,\n",
       " '_tf_policy_handles_more_than_one_loss': False,\n",
       " '_disable_preprocessor_api': False,\n",
       " '_disable_action_flattening': False,\n",
       " '_disable_execution_plan_api': True,\n",
       " 'simple_optimizer': -1,\n",
       " 'replay_sequence_length': None,\n",
       " 'horizon': -1,\n",
       " 'soft_horizon': -1,\n",
       " 'no_done_at_end': -1,\n",
       " 'lr_schedule': None,\n",
       " 'use_critic': True,\n",
       " 'use_gae': True,\n",
       " 'kl_coeff': 0.2,\n",
       " 'sgd_minibatch_size': 256,\n",
       " 'num_sgd_iter': 16,\n",
       " 'shuffle_sequences': True,\n",
       " 'vf_loss_coeff': 1.0,\n",
       " 'entropy_coeff': 0.0,\n",
       " 'entropy_coeff_schedule': None,\n",
       " 'clip_param': 0.3,\n",
       " 'vf_clip_param': 10.0,\n",
       " 'grad_clip': None,\n",
       " 'kl_target': 0.01,\n",
       " 'vf_share_layers': -1,\n",
       " 'lambda': 1.0,\n",
       " 'input': 'sampler',\n",
       " 'multiagent': {'policies': {'default_policy': (None, None, None, None)},\n",
       "  'policy_mapping_fn': <function ray.rllib.algorithms.algorithm_config.AlgorithmConfig.__init__.<locals>.<lambda>(aid, episode, worker, **kwargs)>,\n",
       "  'policies_to_train': None,\n",
       "  'policy_map_capacity': 100,\n",
       "  'policy_map_cache': -1,\n",
       "  'count_steps_by': 'env_steps',\n",
       "  'observation_fn': None},\n",
       " 'callbacks': ray.rllib.algorithms.callbacks.DefaultCallbacks,\n",
       " 'create_env_on_driver': False,\n",
       " 'custom_eval_function': None,\n",
       " 'framework': 'tf',\n",
       " 'num_cpus_for_driver': 1,\n",
       " 'num_workers': 8}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(50):\n",
    "    res = agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n",
      "[1 2]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m done \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[0;32m----> 7\u001b[0m     action \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mcompute_single_action(obs, \n\u001b[1;32m      8\u001b[0m                                          explore\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      9\u001b[0m     \u001b[39mprint\u001b[39m(action)\n\u001b[1;32m     10\u001b[0m     obs, reward, done, terminated, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m~/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:1577\u001b[0m, in \u001b[0;36mAlgorithm.compute_single_action\u001b[0;34m(self, observation, state, prev_action, prev_reward, info, input_dict, policy_id, full_fetch, explore, timestep, episode, unsquash_action, clip_action, unsquash_actions, clip_actions, **kwargs)\u001b[0m\n\u001b[1;32m   1569\u001b[0m     action, state, extra \u001b[39m=\u001b[39m policy\u001b[39m.\u001b[39mcompute_single_action(\n\u001b[1;32m   1570\u001b[0m         input_dict\u001b[39m=\u001b[39minput_dict,\n\u001b[1;32m   1571\u001b[0m         explore\u001b[39m=\u001b[39mexplore,\n\u001b[1;32m   1572\u001b[0m         timestep\u001b[39m=\u001b[39mtimestep,\n\u001b[1;32m   1573\u001b[0m         episode\u001b[39m=\u001b[39mepisode,\n\u001b[1;32m   1574\u001b[0m     )\n\u001b[1;32m   1575\u001b[0m \u001b[39m# Individual args.\u001b[39;00m\n\u001b[1;32m   1576\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1577\u001b[0m     action, state, extra \u001b[39m=\u001b[39m policy\u001b[39m.\u001b[39;49mcompute_single_action(\n\u001b[1;32m   1578\u001b[0m         obs\u001b[39m=\u001b[39;49mobservation,\n\u001b[1;32m   1579\u001b[0m         state\u001b[39m=\u001b[39;49mstate,\n\u001b[1;32m   1580\u001b[0m         prev_action\u001b[39m=\u001b[39;49mprev_action,\n\u001b[1;32m   1581\u001b[0m         prev_reward\u001b[39m=\u001b[39;49mprev_reward,\n\u001b[1;32m   1582\u001b[0m         info\u001b[39m=\u001b[39;49minfo,\n\u001b[1;32m   1583\u001b[0m         explore\u001b[39m=\u001b[39;49mexplore,\n\u001b[1;32m   1584\u001b[0m         timestep\u001b[39m=\u001b[39;49mtimestep,\n\u001b[1;32m   1585\u001b[0m         episode\u001b[39m=\u001b[39;49mepisode,\n\u001b[1;32m   1586\u001b[0m     )\n\u001b[1;32m   1588\u001b[0m \u001b[39m# If we work in normalized action space (normalize_actions=True),\u001b[39;00m\n\u001b[1;32m   1589\u001b[0m \u001b[39m# we re-translate here into the env's action space.\u001b[39;00m\n\u001b[1;32m   1590\u001b[0m \u001b[39mif\u001b[39;00m unsquash_action:\n",
      "File \u001b[0;32m~/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/policy.py:507\u001b[0m, in \u001b[0;36mPolicy.compute_single_action\u001b[0;34m(self, obs, state, prev_action, prev_reward, info, input_dict, episode, explore, timestep, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[39mif\u001b[39;00m episode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m     episodes \u001b[39m=\u001b[39m [episode]\n\u001b[0;32m--> 507\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_actions_from_input_dict(\n\u001b[1;32m    508\u001b[0m     input_dict\u001b[39m=\u001b[39;49mSampleBatch(input_dict),\n\u001b[1;32m    509\u001b[0m     episodes\u001b[39m=\u001b[39;49mepisodes,\n\u001b[1;32m    510\u001b[0m     explore\u001b[39m=\u001b[39;49mexplore,\n\u001b[1;32m    511\u001b[0m     timestep\u001b[39m=\u001b[39;49mtimestep,\n\u001b[1;32m    512\u001b[0m )\n\u001b[1;32m    514\u001b[0m \u001b[39m# Some policies don't return a tuple, but always just a single action.\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[39m# E.g. ES and ARS.\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/policy/tf_policy.py:326\u001b[0m, in \u001b[0;36mTFPolicy.compute_actions_from_input_dict\u001b[0;34m(self, input_dict, explore, timestep, episodes, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m to_fetch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_compute_actions(\n\u001b[1;32m    322\u001b[0m     builder, input_dict\u001b[39m=\u001b[39minput_dict, explore\u001b[39m=\u001b[39mexplore, timestep\u001b[39m=\u001b[39mtimestep\n\u001b[1;32m    323\u001b[0m )\n\u001b[1;32m    325\u001b[0m \u001b[39m# Execute session run to get action (and other fetches).\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m fetched \u001b[39m=\u001b[39m builder\u001b[39m.\u001b[39;49mget(to_fetch)\n\u001b[1;32m    328\u001b[0m \u001b[39m# Update our global timestep by the batch size.\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_timestep \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    330\u001b[0m     \u001b[39mlen\u001b[39m(obs_batch)\n\u001b[1;32m    331\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obs_batch, \u001b[39mlist\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[39melse\u001b[39;00m obs_batch\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    335\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/tf_run_builder.py:42\u001b[0m, in \u001b[0;36m_TFRunBuilder.get\u001b[0;34m(self, to_fetch)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executed \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executed \u001b[39m=\u001b[39m _run_timeline(\n\u001b[1;32m     43\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession,\n\u001b[1;32m     44\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfetches,\n\u001b[1;32m     45\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdebug_name,\n\u001b[1;32m     46\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_dict,\n\u001b[1;32m     47\u001b[0m             os\u001b[39m.\u001b[39;49menviron\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mTF_TIMELINE_DIR\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     48\u001b[0m         )\n\u001b[1;32m     49\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     50\u001b[0m         logger\u001b[39m.\u001b[39mexception(\n\u001b[1;32m     51\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mError fetching: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, feed_dict=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     52\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfetches, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeed_dict\n\u001b[1;32m     53\u001b[0m             )\n\u001b[1;32m     54\u001b[0m         )\n",
      "File \u001b[0;32m~/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/ray/rllib/utils/tf_run_builder.py:112\u001b[0m, in \u001b[0;36m_run_timeline\u001b[0;34m(sess, ops, debug_name, feed_dict, timeline_dir)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[39mif\u001b[39;00m log_once(\u001b[39m\"\u001b[39m\u001b[39mtf_timeline\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    108\u001b[0m         logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    109\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExecuting TF run without tracing. To dump TF timeline traces \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mto disk, set the TF_TIMELINE_DIR environment variable.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m         )\n\u001b[0;32m--> 112\u001b[0m     fetches \u001b[39m=\u001b[39m sess\u001b[39m.\u001b[39;49mrun(ops, feed_dict\u001b[39m=\u001b[39;49mfeed_dict)\n\u001b[1;32m    113\u001b[0m \u001b[39mreturn\u001b[39;00m fetches\n",
      "File \u001b[0;32m~/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/tensorflow/python/client/session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39mNone\u001b[39;49;00m, fetches, feed_dict, options_ptr,\n\u001b[1;32m    969\u001b[0m                      run_metadata_ptr)\n\u001b[1;32m    970\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[1;32m    971\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m~/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/tensorflow/python/client/session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[39m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[39m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[39mif\u001b[39;00m final_fetches \u001b[39mor\u001b[39;00m final_targets \u001b[39mor\u001b[39;00m (handle \u001b[39mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1191\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_run(handle, final_targets, final_fetches,\n\u001b[1;32m   1192\u001b[0m                          feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m   results \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/tensorflow/python/client/session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1368\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1371\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m   1372\u001b[0m                        run_metadata)\n\u001b[1;32m   1373\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m~/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/tensorflow/python/client/session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_call\u001b[39m(\u001b[39mself\u001b[39m, fn, \u001b[39m*\u001b[39margs):\n\u001b[1;32m   1377\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m   1379\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOpError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1380\u001b[0m     message \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39mas_text(e\u001b[39m.\u001b[39mmessage)\n",
      "File \u001b[0;32m~/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/tensorflow/python/client/session.py:1361\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[1;32m   1359\u001b[0m   \u001b[39m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[1;32m   1360\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1361\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m   1362\u001b[0m                                   target_list, run_metadata)\n",
      "File \u001b[0;32m~/miniforge3/envs/hanoi_tower/lib/python3.10/site-packages/tensorflow/python/client/session.py:1454\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_tf_sessionrun\u001b[39m(\u001b[39mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1453\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1454\u001b[0m   \u001b[39mreturn\u001b[39;00m tf_session\u001b[39m.\u001b[39;49mTF_SessionRun_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session, options, feed_dict,\n\u001b[1;32m   1455\u001b[0m                                           fetch_list, target_list,\n\u001b[1;32m   1456\u001b[0m                                           run_metadata)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = create_env(env_config)\n",
    "obs, _ = env.reset()\n",
    "\n",
    "episode_reward = 0\n",
    "done = False\n",
    "while not done:\n",
    "    action = agent.compute_single_action(obs, \n",
    "                                         explore=False)\n",
    "    print(action)\n",
    "    obs, reward, done, terminated, info = env.step(action)\n",
    "    episode_reward += reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [1, 2, 3]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, 2, (3, 2), int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = HanoiTower(config=env_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "env.observation_space.contains(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hanoi_tower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
